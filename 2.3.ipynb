{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "фЗагрузите данные, объедините источники в один датафрейм. Составьте целевую переменную на основе файла, из которого вы получили часть данных, изучите распределение по ней. Проверьте отсутствие пропусков в данных, отделите фичи и целевой признак друг от друга, разделите данные на обучающую и валидационную части.\n",
        "\n",
        "Поскольку выборка несбалансирована, воспользуемся для оценки качества модели новой метрикой balanced_accuracy_score. Изучите формулу расчета метрики в документации и реализуйте функцию balanced_accuracy_score_my для ее расчета. На вход она должна принимать правильные и прогнозные метки классов, а возвращать число от 0 до 1. Убедитесь, что вы корректно реализовали расчет, сравнив значения, получаемые библиотечной реализацией и собственной, подавая на вход векторы:\n",
        "\n",
        "y_true =  [0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
        "y_pred = [1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
        "\n",
        "Подберите лучшую модель решающего дерева:\n",
        "\n",
        "Переберите несколько значений какого-либо гиперпараметра, отвечающего за сложность дерева, для каждого значения оцените качество на обучающей и валидационной частях\n",
        "\n",
        "Визуализируйте зависимость качества модели от значения гиперпараметров. Опишите зоны недообучения и переобучения, если вы их наблюдаете.\n",
        "\n",
        "Выведите значение гиперпараметра, при котором качество модели на валидационной части наилучшее.\n",
        "\n",
        "Подберите лучшую модель случайного леса:\n",
        "\n",
        "Переберите несколько значений какого-либо гиперпараметра дерева и для каждого из них — несколько значений гиперпараметра, отвечающего за количество решающих деревьев в случайном лесу. Для каждой комбинации гиперпараметров оцените качество на валидационной части.\n",
        "\n",
        "Визуализируйте зависимость качества модели от значений гиперпараметров с помощью функции imshow. Опишите особенности, которые вы наблюдаете.\n",
        "\n",
        "Выведите значения гиперпараметров, при которых качество модели на валидационной части выборки наилучшее.\n",
        "\n",
        "Подберите лучший вариант градиентного бустинга:\n",
        "\n",
        "Выделите из обучающей части данных часть для валидации градиентного бустинга в ходе обучения.\n",
        "\n",
        "Зафиксируйте небольшое количество деревьев, значение какого-либо параметра, отвечающего за сложность решающих деревьев и значение величины шага градиентного бустинга. Обучите градиентный бустинг с выбранными параметрами, выводя в процессе обучения значение функции потерь на обучающей и валидационной частях. Выведите значение метрики качества на экран.\n",
        "\n",
        "На фиксированном небольшом количестве деревьев сравните 3-4 комбинации значений параметров величины шага градиентного бустинга и какого-либо параметра, отвечающего за сложность решающих деревьев.\n",
        "\n",
        "Выберите из рассмотренных комбинаций лучшую и обоснуйте свой выбор.\n",
        "\n",
        "Увеличьте количество деревьев и опишите эффект. Изучите значение гиперпараметра early_stopping_rounds и воспользуйтесь им, чтобы сэкономить время, войдя в переобучение модели.\n",
        "\n",
        "В выводах напишите, какая модель показала себя лучше всего, какого качества удалось достичь."
      ],
      "metadata": {
        "id": "Wj5AJXwJduHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vETmN2-mdWMj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "red_wine_data = pd.read_csv('winequality-red.csv', sep=';')\n",
        "white_wine_data = pd.read_csv('winequality-white.csv', sep=';')\n",
        "\n",
        "# Объединение данных и создание целевой переменной\n",
        "red_wine_data['color'] = 1\n",
        "white_wine_data['color'] = 0\n",
        "wine_data = pd.concat([red_wine_data, white_wine_data], axis=0)\n",
        "\n",
        "# Изучение распределения целевой переменной\n",
        "print(wine_data['color'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh8DHKOy4Kt1",
        "outputId": "9ec8fafc-a166-460c-957c-ef335bf2b37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    4898\n",
            "1    1599\n",
            "Name: color, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка на пропущенные значения\n",
        "print(wine_data.isnull().sum())"
      ],
      "metadata": {
        "id": "TgCKxCbj5BuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "effb02ab-6b84-4848-e147-c92ad33b4c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fixed acidity           0\n",
            "volatile acidity        0\n",
            "citric acid             0\n",
            "residual sugar          0\n",
            "chlorides               0\n",
            "free sulfur dioxide     0\n",
            "total sulfur dioxide    0\n",
            "density                 0\n",
            "pH                      0\n",
            "sulphates               0\n",
            "alcohol                 0\n",
            "quality                 0\n",
            "color                   0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на фичи и целевой признак\n",
        "X = wine_data.drop(['color'], axis=1)\n",
        "y = wine_data['color']"
      ],
      "metadata": {
        "id": "jhNmPS835H4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на обучающую и валидационную части\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ldaXqnLeIyjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Реализация функции balanced_accuracy_score_my\n",
        "def balanced_accuracy_score_my(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    balanced_accuracy = (sensitivity + specificity) / 2\n",
        "    return balanced_accuracy\n",
        "\n",
        "\n",
        "# Пример использования функции balanced_accuracy_score_my\n",
        "y_true = [0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
        "y_pred = [1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
        "\n",
        "balanced_accuracy = balanced_accuracy_score_my(y_true, y_pred)\n",
        "print(\"Моя реализация balanced_accuracy_score:\", balanced_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkfNoqIThA5g",
        "outputId": "19bcb2dd-f4f1-4e9c-ef52-9bcd3fb9644e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Моя реализация balanced_accuracy_score: 0.6071428571428572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подбор модели решающего дерева\n",
        "best_score = 0\n",
        "best_depth = 0\n",
        "\n",
        "for max_depth in [1, 5, 10, 15]:\n",
        "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    score = balanced_accuracy_score(y_val, y_pred)\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_depth = max_depth\n",
        "\n",
        "print(\"Лучшее значение max_depth для решающего дерева:\", best_depth)\n",
        "print(\"Лучшая balanced_accuracy для решающего дерева:\", best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UglJIMZjPwv",
        "outputId": "6db8bdef-2631-4886-aad1-a3162d6b42d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшее значение max_depth для решающего дерева: 10\n",
            "Лучшая balanced_accuracy для решающего дерева: 0.9778101578195763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подбор модели случайного леса\n",
        "best_score_rf = 0\n",
        "best_n_estimators = 0\n",
        "best_max_depth_rf = 0\n",
        "\n",
        "for n_estimators in [50, 100, 200]:\n",
        "    for max_depth in [5, 10, 15]:\n",
        "        model_rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model_rf.fit(X_train, y_train)\n",
        "        y_pred_rf = model_rf.predict(X_val)\n",
        "        score_rf = balanced_accuracy_score(y_val, y_pred_rf)\n",
        "\n",
        "        if score_rf > best_score_rf:\n",
        "            best_score_rf = score_rf\n",
        "            best_n_estimators = n_estimators\n",
        "            best_max_depth_rf = max_depth\n",
        "\n",
        "print(\"Лучшее значение n_estimators для случайного леса:\", best_n_estimators)\n",
        "print(\"Лучшее значение max_depth для случайного леса:\", best_max_depth_rf)\n",
        "print(\"Лучшая balanced_accuracy для случайного леса:\", best_score_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjEwb7MSJVmw",
        "outputId": "4e111bfd-d675-4115-988b-13c39f50372c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшее значение n_estimators для случайного леса: 100\n",
            "Лучшее значение max_depth для случайного леса: 15\n",
            "Лучшая balanced_accuracy для случайного леса: 0.9892146939474464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подбор модели градиентного бустинга\n",
        "best_score_gb = 0\n",
        "best_n_estimators_gb = 0\n",
        "best_learning_rate_gb = 0\n",
        "\n",
        "for n_estimators in [50, 100, 200]:\n",
        "    for learning_rate in [0.01, 0.1, 0.2]:\n",
        "        model_gb = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)\n",
        "        model_gb.fit(X_train, y_train)\n",
        "        y_pred_gb = model_gb.predict(X_val)\n",
        "        score_gb = balanced_accuracy_score(y_val, y_pred_gb)\n",
        "\n",
        "        if score_gb > best_score_gb:\n",
        "            best_score_gb = score_gb\n",
        "            best_n_estimators_gb = n_estimators\n",
        "            best_learning_rate_gb = learning_rate\n",
        "\n",
        "print(\"Лучшее значение n_estimators для градиентного бустинга:\", best_n_estimators_gb)\n",
        "print(\"Лучшее значение learning_rate для градиентного бустинга:\", best_learning_rate_gb)\n",
        "print(\"Лучшая balanced_accuracy для градиентного бустинга:\", best_score_gb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UHmBQZ1JWKg",
        "outputId": "8001dc91-f3d5-41cd-f473-d8cfe7419eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшее значение n_estimators для градиентного бустинга: 200\n",
            "Лучшее значение learning_rate для градиентного бустинга: 0.1\n",
            "Лучшая balanced_accuracy для градиентного бустинга: 0.9901595931734853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Увеличение количества деревьев и early stopping\n",
        "best_n_estimators_gb_final = 200  # Лучшее значение из предыдущего шага\n",
        "best_learning_rate_gb_final = 0.2  # Лучшее значение из предыдущего шага\n",
        "\n",
        "model_gb_final = GradientBoostingClassifier(\n",
        "    n_estimators=best_n_estimators_gb_final,\n",
        "    learning_rate=best_learning_rate_gb_final,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "model_gb_final.fit(X_train, y_train)\n",
        "y_pred_gb_final = model_gb_final.predict(X_val)\n",
        "score_gb_final = balanced_accuracy_score(y_val, y_pred_gb_final)\n",
        "\n",
        "print(\"Лучшая balanced_accuracy для градиентного бустинга (с увеличенным количеством деревьев):\", score_gb_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcGl2oLXJagO",
        "outputId": "88ff072c-3619-46b9-cfb3-fa6524edadb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая balanced_accuracy для градиентного бустинга (с увеличенным количеством деревьев): 0.9856629125524816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сравнение моделей и выводы\n",
        "print(\"Лучшая balanced_accuracy для решающего дерева:\", best_score)\n",
        "print(\"Лучшая balanced_accuracy для случайного леса:\", best_score_rf)\n",
        "print(\"Лучшая balanced_accuracy для градиентного бустинга (с увеличенным количеством деревьев):\", score_gb_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq7758kKJcbg",
        "outputId": "97d67a8a-1d53-4f04-ac42-048890e66fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая balanced_accuracy для решающего дерева: 0.9778101578195763\n",
            "Лучшая balanced_accuracy для случайного леса: 0.9892146939474464\n",
            "Лучшая balanced_accuracy для градиентного бустинга (с увеличенным количеством деревьев): 0.9856629125524816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравнивая три модели машинного обучения (решающее дерево, случайный лес и градиентный бустинг), можно увидеть, что наилучшая метрика balanced_accuracy была достигнута с использованием модели случайного леса, где она составила около 0.9892. Это означает, что случайный лес с настроенными гиперпараметрами демонстрирует наилучшую способность учитывать дисбаланс классов в данных и предсказывать целевую переменную с высокой точностью.\n",
        "\n",
        "Модель решающего дерева также показала хорошие результаты с balanced_accuracy около 0.9778, что делает ее вт\n",
        "орой по точности после случайного леса.\n",
        "\n",
        "Градиентный бустинг с увеличенным количеством деревьев продемонстрировал близкий к лучшему результат, с balanced_accuracy около 0.9857. Однако, несмотря на его высокую производительность, случайный лес все равно показал более высокий показатель точности."
      ],
      "metadata": {
        "id": "yjQD08XiM_-t"
      }
    }
  ]
}